{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Pattern Recognition using Hough Transform and Tracks Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Track pattern recognition is an early step of the reconstruction of data coming from a particle detector. It recognizes tracks among the subdetectors hits. Reconstructed track parameters allow to estimate the particle deviation in a magnetic field, and thus reconstruct its charge and momentum. This information is used for the reconstruction of the decay vertex, to identify the mother particle and for further particle identification.\n",
    "\n",
    "There is wide variety of the track pattern recognition methods. They differ in how they process the hits, what kind of tracks they are able to recognize and which requirements these tracks should satisfy. Therefore, specifics of an experiment and the detector geometry affect the tracking performance and track pattern recognition methods should be adapted to it accordingly.\n",
    "\n",
    "In this notebook a track pattern recognition for a 2D detector with circular geometry and uniform magnetic field is considered. The detector schema with hits and tracks of an event is shown in the figure below. The challenge is to recognize tracks of an event with the highest efficiecny. It supposed that one hit can belong to only one track. \n",
    "\n",
    "<img src=\"pic/detector.png\" /> <br>\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook demonstrate how Hough Transform and Machine Learning can be used for track pattern recognition. The notebook describes input data, the track pattern recognition method and qualyti metrics, and shows how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import user_test_submission as submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>layer</th>\n",
       "      <th>iphi</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53253</td>\n",
       "      <td>53.900430</td>\n",
       "      <td>-265.585662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>37216</td>\n",
       "      <td>-47.614439</td>\n",
       "      <td>-402.191329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7181</td>\n",
       "      <td>-4.253919</td>\n",
       "      <td>-38.767308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7937</td>\n",
       "      <td>44.418132</td>\n",
       "      <td>148.499258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7657</td>\n",
       "      <td>7.588600</td>\n",
       "      <td>-38.254583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  cluster_id  layer   iphi          x           y\n",
       "0         3           4      4  53253  53.900430 -265.585662\n",
       "1         3           1      5  37216 -47.614439 -402.191329\n",
       "2         3           1      0   7181  -4.253919  -38.767308\n",
       "3         3           3      2   7937  44.418132  148.499258\n",
       "4         3           4      0   7657   7.588600  -38.254583"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('public_train.csv', index_col=False)\n",
    "data = data[data['event_id'].values < 100]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data[[u'event_id', u'layer', u'iphi', u'x', u'y']].values\n",
    "y = data[[u'event_id', u'cluster_id']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Train/Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "event_ids = numpy.unique(data['event_id'].values)\n",
    "\n",
    "event_ids_train, event_ids_test = train_test_split(event_ids, \n",
    "                                                   test_size=0.5, \n",
    "                                                   random_state=42)\n",
    "\n",
    "X_train, y_train = X[data['event_id'].isin(event_ids_train)], y[data['event_id'].isin(event_ids_train)]\n",
    "X_test, y_test = X[data['event_id'].isin(event_ids_test)], y[data['event_id'].isin(event_ids_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Transform with Tracks Classification\n",
    "\n",
    "# Hough Transform\n",
    "\n",
    "Consider a track pattern recognition method using the Hough Tramsform in polar system. In this system a circular track can be parametrized as follow:\n",
    "\n",
    "$$\n",
    "r = 2r_{0}Cos(\\phi - \\theta)\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $r$ and $\\phi$ : are coordinates of a hit in the polar system.\n",
    "* $r_{0}$ and $\\theta$ : are coordinates of a center of a circular track in the polar system.\n",
    "\n",
    "A linear track corresponds to the $r_{0} = \\infty$.\n",
    "\n",
    "Transformation of cartesian coordinates of a hit to polar coordinates defined as:\n",
    "\n",
    "$$\n",
    "\\phi = arctan(\\frac{y}{x})\n",
    "$$\n",
    "$$\n",
    "r = \\sqrt{x^{2} + y^{2}}\n",
    "$$\n",
    "\n",
    "\n",
    "The Hough Transform converts a hit in $(r, \\phi)$ space to a curve in $(\\frac{1}{r_{0}}, \\theta)$ space of the track parameters as follow:\n",
    "\n",
    "$$\n",
    "\\frac{1}{r_{0}} = \\frac{2Cos(\\phi - \\theta)}{r}\n",
    "$$\n",
    "\n",
    "A linear track in this space represents as $(0, \\theta)$ point.\n",
    "\n",
    "This section demonstrates the track pattern recognition method using Hough Transfrom described above and histogramming technique. In this technique each 'hot' bin represents one recognized track as it is shown in the figure:\n",
    "\n",
    "<img src=\"pic/hough.png\" /> <br>\n",
    "\n",
    "But there are a lot of ghosts among the recognized tracks. The idea is to use the recognized tracks classification to reduce a number of ghosts. For this, each recognized track is described by the following features:\n",
    "\n",
    "* Track parameters\n",
    "* Number of hits\n",
    "* RMSE of a track fit\n",
    "\n",
    "These features are used to train a classisifer to separate good track from the ghost ones. Then, the trained classifier is used to reduce number of ghosts among the reconstructed tracks:\n",
    "\n",
    "<img src=\"pic/clf.png\" width=\"50%\" /> <br>\n",
    "\n",
    "After that, the track are processed to generate hit labels. Please, look the method script for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of a base track pattern recognition method and a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from hough import Hough\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "base = Hough(n_theta_bins=5000, n_radius_bins=1000, min_radius=20., min_hits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hough_classification import HoughClassification\n",
    "\n",
    "mh = HoughClassification(base=base, \n",
    "                         classifier=clf, \n",
    "                         proba_threshold=0.8, \n",
    "                         track_eff_threshold=0.8)\n",
    "\n",
    "mh.fit(X_train, y_train)\n",
    "y_pred_test = mh.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759369385604524"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = submission.score_function(y_test, y_pred_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from metrics import RecognitionQuality\n",
    "\n",
    "rq = RecognitionQuality(track_eff_threshold=0.8, min_hits_per_track=4)\n",
    "report_event, report_tracks = rq.calculate(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReconstructionEfficiency    0.900397\n",
       "GhostRate                   0.010714\n",
       "CloneRate                   0.000000\n",
       "AvgTrackEfficiency          0.988721\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_event.mean(axis=0)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
